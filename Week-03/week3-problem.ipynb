{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP0189: Applied Artificial Intelligence\n",
    "## Week 3 (Model Selection and Assessment)\n",
    "\n",
    "### After this week you will be able to ...\n",
    "- encode categorical values with one-hot encoding\n",
    "- know which encoding, scaling, and imputing method you should select in accordacne with the dataset characteristics\n",
    "- impute missing data with KNN\n",
    "- know how to streamline the preprocessing steps in advanced way (Pipeline and ColmnTransformer)\n",
    "- select best model based on various cross-validation methods\n",
    "\n",
    "### Acknowledgements\n",
    "- https://scikit-learn.org/stable/\n",
    "- https://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optional: For black-style code formatting within the notebook env.\n",
    "!pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: For black-style code formatting within the notebook env.\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously, we used version 1.1.3 to use boston dataset as an example.\n",
    "# Since there has been many updates in core functions after version 1.2,\n",
    "# we are updating the scikit-learn to the latest version.\n",
    "# Otherwise you will get some errors and FutureWarnings.\n",
    "!pip install scikit-learn==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Encoding and Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load and Split the Dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TASK 1: Load Dataset\n",
    "# We are going to use the same adult dataset as previous week.\n",
    "# We have cleaned the dataset, but did not touch the missing values.\n",
    "df = pd.read_csv(\"../data/clean_adult.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Encode categorical variables (label/ordinal encoding & one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: We need special care when we are encoding categorical variables \n",
    "\n",
    "**1. Take care of the missing values**\n",
    "- Beware not to encode missing values unless you are intending to do so.\n",
    "- Sometimes you want to encode missing values to a separate cateogory. For example, when you want to predict if passengers of titanic had survived or not, missing data of certain features can actually have meaning, i.e., Cabin information can be missing because the body was not found.\n",
    "\n",
    "**2. Know which encoding and scaling method you should select**\n",
    "- If your categories are ordinal, then it makes sense to use a LabelEncoder with a MinMaxScaler. For example, you can encode [low, medium, high], as [1,2,3], i.e., distance between low to high is larger than that of medium and high.\n",
    "\n",
    "- However, if you have non-ordinal categorical values, like [White, Hispanic, Black, Asian], then it would be better to use a OneHotEncoder instead of forcing ordinality with a LabelEncoder. Otherwise the algorithms you use (especially distance based algorithms like KNN) will make the assumption that the distance between White and Asian is larger than White and Hispanic, which is nonsensical.\n",
    "\n",
    "**3. Split before you encode to avoid data leakage**\n",
    "- Split the dataset before you encode your data. It is natural for algorithms to see unknown values in the validation/test set that was not appearing in the train set. `sklearn.preprocessing.OneHotEncoder` is good at handling these unknown categories (`handle_unknown` parameter).\n",
    "\n",
    "- Discussion: What if you are certain about all the possible categories that can appear for each feature? Can you encode all the values before splitting the dataset into train and test set?\n",
    "\n",
    "\n",
    "This notebook shows the three points in the following sections with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2-1: Label Encoding (with missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, \n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2-2: One Hot Encoding (with missing values imputation)\n",
    "\n",
    "Tip 1: Impute the missing values (choose the right strategy) before doing OHE  \n",
    "Tip 2: Try creating a separate dataframe with one-hot encoded columns and combine the dataframe with the original dataframe for the final one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another (recommended) Method for Task 2\n",
    "### Using `Pipeline` and `ColmnTransformer` to streamline the workflow.\n",
    "\n",
    "We will do the same operation (with addition of scaling) but with much more succinct way.   \n",
    "We use `Pipeline` and `ColmnTransformer`.  \n",
    "`ColmnTransformer` is needed to apply different preprocessing steps to selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Note: Data Imputation with KNN\n",
    "For the adult dataset, missing data present only in categorical values, so imputing strategy that makes floating point may not make sense.\n",
    "However, for continuous values, you can use various imputation strategies, such as taking simple mean or mean value from K nearest neighbors (KNN).\n",
    "If you use `sklearn.imput.KNNImputer`, each sampleâ€™s missing values are imputed using the `mean` value from `n_neighbors` nearest neighbors found in the training set.\n",
    "If you want to use `mode` value from neighbors (for categorical data imputation) you need to implement the imputer by yourself.\n",
    "\n",
    "- `sklearn-pandas` package (https://pypi.org/project/sklearn-pandas/1.5.0/) provides `CategoricalImputer` class, which is suitable for such processing\n",
    "\n",
    "Here, we use iris dataset to show how to use KNNImputer for continuous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a random mask to make missing data\n",
    "mask = np.random.choice([True, False], size=iris_df.shape[0] * iris_df.shape[1])\n",
    "mask[:500] = True\n",
    "np.random.shuffle(mask)\n",
    "mask = np.reshape(mask, iris_df.shape)\n",
    "iris_df = iris_df.mask(~mask)\n",
    "\n",
    "iris_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X = iris_df[:100], iris_df[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to impute the train and test set separately (not fitting KNN to test set) to avoid data leak.\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_train_X = imputer.fit_transform(train_X)\n",
    "imputed_test_X = imputer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del iris, iris_df, mask, train_X, test_X, imputer, imputed_train_X, imputed_test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create different preprocessing strategies of your own\n",
    "Create different versions of X (X1 and X2) and y using different strategies for data imputation.  \n",
    "Define different preprocessing strategies using the `Pipeline` and `ColmnTransformer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your explorations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: \n",
    "Train different models (KNN, SVM) to predict the y from the two versions of X (X1 and X2) with a fixed value of the regularization parameter. \n",
    "Centre and scale the data before training the models. Create tables or plots to show how accuracy varies for different imputation strategies or different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4-1: Training KNN and SVM Models (with original preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4-2: Investigation\n",
    "Create tables or plots to show how accuracy varies for different imputation strategies or different models. \n",
    "- What is the impact of the imputation strategy on the accuracy? \n",
    "- What is the impact of the model on the accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Cross Validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides a nice visulaisation of various cross validation methods.  \n",
    "This notebook focuses on the three main CV techniques: `KFold`, `StratifiedKFold`, `GroupKFold`, and `StratifiedGroupKFold` for optimizing models' hyper-parameters and to understand how different strategies might affect the models' performance. \n",
    "\n",
    "Visit: https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#visualizing-cross-validation-behavior-in-scikit-learn\n",
    "\n",
    "![kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_006.png)\n",
    "![stra-kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_003.png)\n",
    "![group-kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_004.png)\n",
    "![stra-group-kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_010.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Now do CV to optimize the models hyperparameter using different k (2, 5, 10, 20) for the k-fold CV (KNN, SVM) to predict the y from the two versions of X (X1 and X2) and plot the model performance (mean accuracy and SD) for the different k. Centre and scale the data before training the models. \n",
    "\n",
    "Note: remember that the pre-processing steps, including data centering and scaling should be embedded in the CV. \n",
    "\n",
    "- How does the accuracy vary as the number of folds increase? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Repeat task 5 using stratified CV with k=5. Compute the accuracy of the models implemented in task 5 (with k=5) and check if the model with stratified CV performs better across the different folds. Centre and scale the data before training the models. Create tables or plots to show these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "Repeat task 5 using stratified group CV considering 'Race' as a group with k=5.\n",
    "Compute the accuracy of the models implemented in task 5 (with k=5) and check if the model with stratified group CV performs better across the different races. \n",
    "Centre and scale the data before training the models. \n",
    "Create tables or plots to show these results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c975486aa82b32d30c2438da9d14334177c2b4d93822b75ed42b1917e361f4e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
